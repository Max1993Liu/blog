1. 简要介绍Isolation Tree和Isolation Forest

	传统的异常检测通常依赖于统计检验(T-test, F-test)来发现异常点，Isolation Tree巧妙的利用决策树分裂来寻找离群样本，由于异常点和大多数的正常样本差距较大所以会被更早的孤立出来，如下图所示：

	[Illustration]

	标红的异常点由于其形状不同，可以在第一次按形状分裂的时候就被孤立出来。大家可能要问那我们怎么能提前知道要按形状做区分呢？答案是我们并不需要提前知道！每一次分裂选择的特征和值都是随机的，只要我们生成足够多的Isolation Tree，由于异常点通常在多个特征上都有较大的偏离度，因此从统计学角度来看就更有可能在二叉树较浅的位置就被孤立出来，这也就是Isolation Forest的原理了。Isolation Forest(下称IF)故名思义就是很多颗Isolation Tree的组合，如果一个样本在较多的树中都很早的就被孤立出来，那我们就认为它的异常程度较高。

	在每一个颗Isolation Tree中，样本的异常程度可以用被孤立出的层数来体现，层数越小代表越早被孤立出来即异常程度越高。我们也可以从另一个角度来看，**样本的异常程度等于该样本在树中经过的边数**，这和层数其实是等价的。
	
	scikit-learn的ensemble模块中实现了Isolation Forest的算法，代码也非常简洁明了。``IsolationForest`` 继承了BaseBagging类，每一个子模型都是随机选择分裂点的ExtraTreeRegressor
	[Image]


2. 能够吸收用户反馈的Isolation Forest
	
	异常检测在金融风控领域中的应用十分广泛，典型的检测的对象是有欺诈或高危行为的用户。在这些场景中通常不会仅仅依赖异常检测算法的结果，也需要人工介入进行判断，因为一旦模型将正常的用户误判为高危用户进而采取限制行为，对用户的使用体验是极大的打击。同时这些人工审核的结果对算法来说是宝贵的标签，所以我们希望将这些反馈纳入到模型中持续迭代。在2018年的一篇文章中[1]，作者提出了一种能够根据吸收用户反馈来持续迭代的异常检测框架。接下来我们先简单的描述一下这个框架是什么样的，然后再来看一下怎么用这个框架来持续更新IF。 

	作者提出的框架是基于在线优化的问题，在每一次迭代的过程中有三个步骤：
	1. 选取一个向量W（可以粗略理解为模型的参数，向量W会直接影响到异常值）
	2. 输出检测结果并得到反馈y
	3. 根据反馈计算损失函数L, 并更新向量W

	假设y=1表示样本确实为异常，y=-1表示审核结果正常，那么损失函数应该在y=-1的时候更大，并且应该鼓励模型在y=1的样本上输出更大的异常值。比较常见的是线性损失函数 **L = - y * 【anomaly score】**。在更新向量W时，我们一方面希望能最小化损失函数L，但同时

	介绍完优化框架后，我们来看一下这个框架中的向量W是如何和IF结合到一起的。在第一部分中我们提到过IF计算异常分的逻辑可以理解为样本在树模型里一共经过了多少条边，如果我们给每条边赋予一个权重w, 那所有边的权重集合就是框架中的向量W，异常值就对应了向量W加权的总边数。我们在没有收到任何反馈之前令W为一个值全为1的向量，此时就对应了传统的IF。

	对应第一部分的例子，如果我们得到反馈说红色方块并没有异常，那么我们可以增大边w1的权重（权重越大->加权的深度越大->异常程度越小)来进行相应的调整。

	[weight update]



参考文章：
1. Feedback-Guided Anomaly Discovery via Online Optimization
2. Fei Tony Liu, Kai Ming Ting, and Zhi-Hua Zhou. 2008. Isolation forest